{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab9672-826d-4e2c-93d2-dd8c61304f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import ollama # Ensure ollama >= 0.2.0 installed\n",
    "# import json # No se usa activamente, se puede quitar si no se planea usar\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import traceback\n",
    "import concurrent.futures # Para procesamiento paralelo\n",
    "from typing import Optional, Tuple, List, Dict, Any # Para Type Hinting\n",
    "\n",
    "# --- Constantes Globales ---\n",
    "APP_TITLE: str = \"Analizador y Clasificador Optimizado de Tickets IT\"\n",
    "WINDOW_SIZE: str = \"750x600\" # Ligeramente más grande para el botón Cancelar\n",
    "REQUIRED_COLUMNS: List[str] = [\n",
    "    'Number', 'Priority', 'State', 'Assigned to', 'Short description',\n",
    "    'Task type', 'Subcategory', 'Closed', 'Created', 'Assignment group',\n",
    "    'Work notes list', 'Work notes', 'Description'\n",
    "]\n",
    "LLM_MODEL_GEMMA: str = 'gemma3' # Nombre base del modelo LLM\n",
    "MAX_RETRIES: int = 3\n",
    "RETRY_DELAY: int = 5\n",
    "# ¡NUEVO! Número máximo de hilos para procesar tickets en paralelo\n",
    "# Ajusta según tu CPU y la capacidad de respuesta de tu servidor Ollama\n",
    "MAX_WORKERS: int = 4\n",
    "\n",
    "# --- Constantes para Marcadores y Errores ---\n",
    "EMPTY_TEXT_MARKER: str = \"TEXTO_VACIO\"\n",
    "PROCESSING_ERROR_MARKER: str = \"ERROR_PROCESAMIENTO_INTERNO\"\n",
    "OLLAMA_ERROR_PREFIX: str = \"ERROR_OLLAMA_\"\n",
    "UNEXPECTED_ERROR_PREFIX: str = \"ERROR_INESPERADO_\"\n",
    "LENGTH_MISMATCH_MARKER: str = \"ERROR_LONGITUD_RESULTADOS\"\n",
    "\n",
    "# --- Plantillas de Prompts para el LLM ---\n",
    "# (Sin cambios respecto a la versión anterior, asegúrate que son las correctas)\n",
    "PROMPT_GEMMA_SUMMARY: str = \"\"\"\n",
    "Eres un asistente experto en análisis de tickets de IT. Resume el siguiente ticket de forma concisa para análisis de tendencias futuras. Enfócate en:\n",
    "- Puntos clave técnicos del problema o solicitud.\n",
    "- Posible causa raíz si es identificable.\n",
    "- Acciones técnicas realizadas si se mencionan.\n",
    "\n",
    "Formato de salida: Lista de viñetas (- Punto 1). Sé breve y directo.\n",
    "\n",
    "Ticket:\n",
    "{ticket_text}\n",
    "\n",
    "Resumen conciso:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_GEMMA_CLASSIFICATION: str = \"\"\"\n",
    "Eres un analista de soporte IT experimentado. Lee el siguiente ticket y clasifícalo en UNA categoría principal concisa que describa el área o tipo de problema/solicitud. Sé lo más específico posible dentro de categorías comunes de IT.\n",
    "Algunos ejemplos de categorías (puedes usar otras si son más apropiadas):\n",
    "Gestión de Cuentas, Problema Hardware (PC/Laptop), Problema Hardware (Impresora), Problema Hardware (Otro), Problema Software (Aplicación X), Problema Software (Office), Problema Software (Sistema Operativo), Solicitud Software, Red/Conectividad, Correo Electrónico, Seguridad, Acceso VPN, Impresión, Consulta General, Capacitación, Otros.\n",
    "\n",
    "Ticket:\n",
    "{ticket_text}\n",
    "\n",
    "Categoría Principal:\n",
    "\"\"\"\n",
    "\n",
    "# --- Configuración del Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(threadName)s - %(message)s')\n",
    "\n",
    "# --- Funciones Auxiliares ---\n",
    "\n",
    "def clean_text(text: Optional[Any]) -> str:\n",
    "    \"\"\"\n",
    "    Limpia el texto de entrada (maneja None, NaN). Elimina HTML, texto específico,\n",
    "    y espacios/líneas en blanco excesivos.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Devuelve cadena vacía si no es string (o es NaN, None)\n",
    "    # Elimina líneas específicas (puedes añadir más patrones si es necesario)\n",
    "    text = re.sub(r'\\[ARGONAUTA\\].*?\\n', '', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "    text = re.sub(r'\\[INC\\w*\\]', '', text, flags=re.IGNORECASE)\n",
    "    # Elimina HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        text = soup.get_text(separator=\"\\n\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"BeautifulSoup falló al parsear texto. Error: {e}. Devolviendo texto semi-limpio.\")\n",
    "    # Normaliza saltos de línea y espacios\n",
    "    text = re.sub(r'\\s*\\n\\s*', '\\n', text) # Líneas en blanco con espacios\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text) # Máximo dos saltos de línea seguidos\n",
    "    return text.strip()\n",
    "\n",
    "def safe_get(dct: Dict, *keys: str) -> Optional[Any]:\n",
    "    \"\"\"Accede de forma segura a claves anidadas en un diccionario.\"\"\"\n",
    "    for key in keys:\n",
    "        try:\n",
    "            dct = dct[key]\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "            return None\n",
    "    return dct\n",
    "\n",
    "def call_ollama_with_retry(model_name: str, prompt: str, max_retries: int = MAX_RETRIES, delay: int = RETRY_DELAY) -> str:\n",
    "    \"\"\"\n",
    "    Llama a Ollama con reintentos. Devuelve la respuesta o un string de error.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        # ¡Importante! Verificar cancelación antes de la llamada\n",
    "        if app and app.cancel_requested.is_set(): # Verifica si 'app' existe\n",
    "             return \"OPERACION_CANCELADA\"\n",
    "\n",
    "        try:\n",
    "            response = ollama.chat(model=model_name, messages=[{'role': 'user', 'content': prompt}])\n",
    "            content = safe_get(response, 'message', 'content')\n",
    "\n",
    "            if content is None:\n",
    "                logging.warning(f\"Respuesta inesperada Ollama ({model_name}), falta 'message.content'. Respuesta: {response}\")\n",
    "                raise ValueError(f\"Respuesta inesperada Ollama: falta 'message.content'\") # Forza reintento\n",
    "            if not isinstance(content, str):\n",
    "                 logging.warning(f\"Respuesta Ollama no es string ({model_name}). Contenido: '{content}'\")\n",
    "                 raise ValueError(f\"Respuesta Ollama no es string\") # Forza reintento\n",
    "\n",
    "            return content.strip()\n",
    "\n",
    "        except (ollama.ResponseError, ConnectionError, TimeoutError, ValueError) as e:\n",
    "            retries += 1\n",
    "            logging.warning(f\"Error Ollama ({model_name}) - Intento {retries}/{max_retries}: {e}\")\n",
    "            if app and app.cancel_requested.is_set(): return \"OPERACION_CANCELADA\"\n",
    "            if retries < max_retries:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logging.error(f\"Fallaron {max_retries} intentos con Ollama ({model_name}). Error final: {e}\")\n",
    "                return f\"{OLLAMA_ERROR_PREFIX}{model_name.replace(':', '_').upper()}\"\n",
    "        except Exception as e:\n",
    "             retries += 1\n",
    "             logging.warning(f\"Error inesperado llamando a Ollama ({model_name}) - Intento {retries}/{max_retries}: {e}\\n{traceback.format_exc()}\")\n",
    "             if app and app.cancel_requested.is_set(): return \"OPERACION_CANCELADA\"\n",
    "             if retries < max_retries:\n",
    "                 time.sleep(delay)\n",
    "             else:\n",
    "                 logging.error(f\"Fallaron {max_retries} intentos con Ollama ({model_name}) error inesperado. Error final: {e}\")\n",
    "                 return f\"{UNEXPECTED_ERROR_PREFIX}{model_name.replace(':', '_').upper()}\"\n",
    "    # En teoría, nunca se llega aquí, pero por si acaso:\n",
    "    return f\"{UNEXPECTED_ERROR_PREFIX}FALLO_REINTENTOS_INESPERADO\"\n",
    "\n",
    "\n",
    "def check_model_exists(model_base_name: str, available_models_full_names: List[str]) -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"Verifica si un modelo base (o variante con tag) existe en la lista.\"\"\"\n",
    "    for full_name in available_models_full_names:\n",
    "        if full_name == model_base_name or full_name.startswith(model_base_name + ':'):\n",
    "            return True, full_name\n",
    "    return False, None\n",
    "\n",
    "# --- Clase de la Aplicación GUI ---\n",
    "class TicketAnalyzerApp:\n",
    "    def __init__(self, root: tk.Tk):\n",
    "        self.root = root\n",
    "        self.root.title(APP_TITLE)\n",
    "\n",
    "        # Configuración ventana\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        w, h = map(int, WINDOW_SIZE.split('x'))\n",
    "        x = (screen_width - w) // 2\n",
    "        y = (screen_height - h) // 2\n",
    "        self.root.geometry(f'{w}x{h}+{x}+{y}')\n",
    "        self.root.minsize(w, h)\n",
    "\n",
    "        # Variables de estado Tkinter y de control\n",
    "        self.file_path = tk.StringVar()\n",
    "        self.processing_thread: Optional[threading.Thread] = None\n",
    "        self.start_time: Optional[float] = None\n",
    "        self.gemma_summary_errors: int = 0\n",
    "        self.gemma_classification_errors: int = 0\n",
    "        self.processed_count: int = 0\n",
    "        self.total_tickets_to_process: int = 0\n",
    "        self.actual_model_to_use: str = LLM_MODEL_GEMMA\n",
    "        self.cancel_requested = threading.Event() # Evento para la cancelación\n",
    "\n",
    "        # Configuración Grid Layout\n",
    "        self.root.grid_columnconfigure(0, weight=1)\n",
    "        self.root.grid_rowconfigure(1, weight=1) # Fila del log expandible\n",
    "\n",
    "        # Crear Widgets\n",
    "        self._create_widgets()\n",
    "\n",
    "        # Iniciar verificación de Ollama en hilo separado\n",
    "        self._log_message(\"Iniciando verificación de conexión con Ollama en segundo plano...\")\n",
    "        threading.Thread(target=self._perform_initial_ollama_check_async, daemon=True).start()\n",
    "\n",
    "    # --- Métodos para la GUI (Logging, Progreso, Estado UI) ---\n",
    "\n",
    "    def _log_message(self, message: str, level: str = \"INFO\") -> None:\n",
    "        \"\"\"Registra mensajes en GUI y logger (seguro para hilos).\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        log_entry = f\"[{timestamp}] {message}\\n\"\n",
    "        try:\n",
    "            # Solo el hilo principal de Tkinter puede actualizar la GUI\n",
    "            self.root.after(0, self._insert_log, log_entry)\n",
    "            if level == \"ERROR\": logging.error(message)\n",
    "            elif level == \"WARNING\": logging.warning(message)\n",
    "            else: logging.info(message)\n",
    "        except tk.TclError: # Si la ventana se cierra mientras se intenta loguear\n",
    "            print(log_entry.strip())\n",
    "        except RuntimeError: # Si el event loop de Tkinter ya no corre\n",
    "             print(f\"(Tkinter no disponible) {log_entry.strip()}\")\n",
    "\n",
    "\n",
    "    def _insert_log(self, log_entry: str) -> None:\n",
    "        \"\"\"Inserta texto en el widget ScrolledText (llamado desde _log_message).\"\"\"\n",
    "        if self.log_text and self.log_text.winfo_exists():\n",
    "            current_state = self.log_text['state']\n",
    "            self.log_text.config(state=tk.NORMAL)\n",
    "            self.log_text.insert(tk.END, log_entry)\n",
    "            self.log_text.see(tk.END) # Auto-scroll\n",
    "            self.log_text.config(state=current_state) # Restaurar estado original (usualmente DISABLED)\n",
    "            # self.root.update_idletasks() # Quitado: puede ralentizar si hay muchos logs\n",
    "\n",
    "    def _update_progress(self, value: float) -> None:\n",
    "        \"\"\"Actualiza la barra de progreso (seguro para hilos).\"\"\"\n",
    "        try:\n",
    "            self.root.after(0, self._set_progress, value)\n",
    "        except (tk.TclError, RuntimeError):\n",
    "            pass # Ignorar si la GUI no está disponible\n",
    "\n",
    "    def _set_progress(self, value: float) -> None:\n",
    "        \"\"\"Establece el valor de la barra de progreso.\"\"\"\n",
    "        if self.progress_bar and self.progress_bar.winfo_exists():\n",
    "            self.progress_bar['value'] = value\n",
    "            # self.root.update_idletasks() # Quitado: puede ralentizar\n",
    "\n",
    "    def _set_ui_state(self, state: str) -> None:\n",
    "        \"\"\"Habilita/deshabilita controles de la GUI.\"\"\"\n",
    "        tk_state = tk.NORMAL if state == 'enabled' else tk.DISABLED\n",
    "        entry_state = tk.NORMAL if state == 'enabled' else 'readonly'\n",
    "        run_button_text = \"Ejecutar Proceso (▶)\"\n",
    "        run_button_state = tk.DISABLED\n",
    "\n",
    "        if state == 'processing':\n",
    "            tk_state = tk.DISABLED\n",
    "            entry_state = 'readonly'\n",
    "            run_button_text = \"Procesando...\"\n",
    "            run_button_state = tk.DISABLED\n",
    "            cancel_button_state = tk.NORMAL # Habilitar Cancelar\n",
    "        elif state == 'enabled':\n",
    "            cancel_button_state = tk.DISABLED # Deshabilitar Cancelar\n",
    "            # Habilitar Ejecutar solo si hay archivo\n",
    "            if self.file_path.get():\n",
    "                run_button_state = tk.NORMAL\n",
    "        else: # disabled\n",
    "            cancel_button_state = tk.DISABLED\n",
    "\n",
    "        try:\n",
    "            # Usar `winfo_exists()` por si la ventana se cierra durante el proceso\n",
    "            if self.browse_button and self.browse_button.winfo_exists():\n",
    "                self.browse_button.config(state=tk_state)\n",
    "            if self.file_entry and self.file_entry.winfo_exists():\n",
    "                self.file_entry.config(state=entry_state)\n",
    "            if self.run_button and self.run_button.winfo_exists():\n",
    "                self.run_button.config(state=run_button_state, text=run_button_text)\n",
    "            if self.cancel_button and self.cancel_button.winfo_exists():\n",
    "                self.cancel_button.config(state=cancel_button_state)\n",
    "        except (tk.TclError, RuntimeError):\n",
    "            pass # Ignorar si la GUI no está disponible\n",
    "\n",
    "    # --- Creación de Widgets ---\n",
    "    def _create_widgets(self) -> None:\n",
    "        \"\"\"Crea y organiza los widgets de la GUI.\"\"\"\n",
    "        # --- Marco Superior (Archivo) ---\n",
    "        top_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        top_frame.grid(row=0, column=0, columnspan=2, sticky=\"ew\")\n",
    "        top_frame.grid_columnconfigure(1, weight=1)\n",
    "        ttk.Label(top_frame, text=\"Archivo Excel:\").grid(row=0, column=0, padx=(0, 5), sticky=\"w\")\n",
    "        self.file_entry = ttk.Entry(top_frame, textvariable=self.file_path, state=\"readonly\", width=60)\n",
    "        self.file_entry.grid(row=0, column=1, padx=5, sticky=\"ew\")\n",
    "        self.browse_button = ttk.Button(top_frame, text=\"Examinar (🖿)\", command=self._browse_file, width=15)\n",
    "        self.browse_button.grid(row=0, column=2, padx=(5, 0))\n",
    "\n",
    "        # --- Marco Medio (Log y Progreso) ---\n",
    "        middle_frame = ttk.Frame(self.root, padding=(10, 0, 10, 10))\n",
    "        middle_frame.grid(row=1, column=0, columnspan=2, sticky=\"nsew\")\n",
    "        middle_frame.grid_rowconfigure(0, weight=1)\n",
    "        middle_frame.grid_columnconfigure(0, weight=1)\n",
    "        # Log\n",
    "        log_container = ttk.LabelFrame(middle_frame, text=\"Registro de Proceso\", padding=5)\n",
    "        log_container.grid(row=0, column=0, sticky=\"nsew\", pady=(0, 10))\n",
    "        log_container.grid_rowconfigure(0, weight=1)\n",
    "        log_container.grid_columnconfigure(0, weight=1)\n",
    "        self.log_text = scrolledtext.ScrolledText(log_container, wrap=tk.WORD, state=tk.DISABLED, height=15, font=(\"TkDefaultFont\", 9))\n",
    "        self.log_text.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        # Barra de progreso\n",
    "        self.progress_bar = ttk.Progressbar(middle_frame, orient=\"horizontal\", length=300, mode=\"determinate\")\n",
    "        self.progress_bar.grid(row=1, column=0, sticky=\"ew\", pady=(5, 0))\n",
    "\n",
    "        # --- Marco Inferior (Botones) ---\n",
    "        bottom_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        # Ahora la fila 2, columna 0, pero necesita columnspan=2 si quieres centrar botones\n",
    "        bottom_frame.grid(row=2, column=0, columnspan=2, sticky=\"ew\")\n",
    "        # Centrar los botones en el espacio disponible\n",
    "        bottom_frame.grid_columnconfigure(0, weight=1) # Espacio a la izquierda\n",
    "        bottom_frame.grid_columnconfigure(1, weight=0) # Botón Ejecutar\n",
    "        bottom_frame.grid_columnconfigure(2, weight=0) # Botón Cancelar\n",
    "        bottom_frame.grid_columnconfigure(3, weight=1) # Espacio a la derecha\n",
    "\n",
    "        self.run_button = ttk.Button(bottom_frame, text=\"Ejecutar Proceso (▶)\", command=self._start_processing, state=tk.DISABLED)\n",
    "        self.run_button.grid(row=0, column=1, padx=5) # Columna 1\n",
    "\n",
    "        self.cancel_button = ttk.Button(bottom_frame, text=\"Cancelar (⏹)\", command=self._request_cancel, state=tk.DISABLED)\n",
    "        self.cancel_button.grid(row=0, column=2, padx=5) # Columna 2\n",
    "\n",
    "    # --- Lógica de Verificación de Ollama ---\n",
    "\n",
    "    def _verify_ollama_model(self) -> Tuple[bool, str, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Verifica conexión con Ollama y existencia del modelo base.\n",
    "        Returns:\n",
    "            Tuple[bool, str, Optional[str]]: (éxito, mensaje, nombre_modelo_encontrado)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            models_response = ollama.list()\n",
    "            # Extraer nombres de modelos de forma robusta\n",
    "            available_models_full = []\n",
    "            models_list = []\n",
    "            if isinstance(models_response, dict) and 'models' in models_response:\n",
    "                models_list = models_response['models']\n",
    "            elif hasattr(models_response, 'models'): # Si es un objeto con atributo 'models'\n",
    "                 models_list = models_response.models\n",
    "\n",
    "            if isinstance(models_list, list):\n",
    "                 for m in models_list:\n",
    "                    model_name_attr = None\n",
    "                    if isinstance(m, dict) and 'name' in m: model_name_attr = m['name'] # Estructura común\n",
    "                    elif isinstance(m, dict) and 'model' in m: model_name_attr = m['model'] # Otra estructura posible\n",
    "                    elif hasattr(m, 'model'): model_name_attr = m.model\n",
    "                    elif hasattr(m, 'name'): model_name_attr = m.name\n",
    "\n",
    "                    if model_name_attr: available_models_full.append(model_name_attr)\n",
    "                    else: logging.warning(f\"Elemento de modelo inesperado en lista Ollama: {m}\")\n",
    "            else:\n",
    "                 return False, f\"Respuesta inesperada de Ollama al listar modelos: {type(models_list)}\", None\n",
    "\n",
    "            model_found, found_model_name = check_model_exists(LLM_MODEL_GEMMA, available_models_full)\n",
    "\n",
    "            if model_found:\n",
    "                return True, f\"Modelo base '{LLM_MODEL_GEMMA}' encontrado (se usará: '{found_model_name}').\", found_model_name\n",
    "            else:\n",
    "                return False, f\"Modelo base '{LLM_MODEL_GEMMA}' (o variante) NO encontrado. Instálalo (ej: 'ollama pull {LLM_MODEL_GEMMA}').\", None\n",
    "\n",
    "        except (ollama.ResponseError, ConnectionError, TimeoutError) as e:\n",
    "            return False, f\"Error de conexión/respuesta con Ollama: {e}. ¿Está Ollama ejecutándose?\", None\n",
    "        except Exception as e:\n",
    "            return False, f\"Error inesperado verificando Ollama: {e}\\n{traceback.format_exc()}\", None\n",
    "\n",
    "    def _perform_initial_ollama_check_async(self) -> None:\n",
    "        \"\"\"Realiza la verificación inicial en un hilo separado.\"\"\"\n",
    "        is_ok, message, found_model_name = self._verify_ollama_model()\n",
    "        log_level = \"INFO\" if is_ok else \"ERROR\"\n",
    "        self._log_message(f\"Verificación inicial Ollama: {message}\", level=log_level)\n",
    "        if is_ok and found_model_name:\n",
    "            self.actual_model_to_use = found_model_name\n",
    "        elif not is_ok:\n",
    "             # Opcional: Mostrar un popup de error no bloqueante si falla al inicio\n",
    "             # self.root.after(0, lambda: messagebox.showerror(\"Error Ollama Inicial\", message, parent=self.root))\n",
    "             pass # Por ahora solo log\n",
    "\n",
    "    # --- Lógica de Selección de Archivo ---\n",
    "    def _browse_file(self) -> None:\n",
    "        \"\"\"Abre diálogo para seleccionar archivo Excel.\"\"\"\n",
    "        fpath = filedialog.askopenfilename(\n",
    "            parent=self.root,\n",
    "            title=\"Seleccionar archivo Excel\",\n",
    "            filetypes=[(\"Archivos Excel\", \"*.xlsx\"), (\"Todos los archivos\", \"*.*\")]\n",
    "        )\n",
    "        if fpath:\n",
    "            if not fpath.lower().endswith(\".xlsx\"):\n",
    "                messagebox.showerror(\"Error de Archivo\", \"Selecciona un archivo .xlsx válido.\", parent=self.root)\n",
    "                self.file_path.set(\"\")\n",
    "            else:\n",
    "                self.file_path.set(fpath)\n",
    "                # Limpiar estado anterior\n",
    "                if self.log_text.winfo_exists():\n",
    "                    self.log_text.config(state=tk.NORMAL)\n",
    "                    self.log_text.delete('1.0', tk.END)\n",
    "                    self.log_text.config(state=tk.DISABLED)\n",
    "                self._update_progress(0)\n",
    "                self.gemma_summary_errors = 0\n",
    "                self.gemma_classification_errors = 0\n",
    "                self.processed_count = 0\n",
    "                self.total_tickets_to_process = 0\n",
    "                self._log_message(f\"Archivo seleccionado: {fpath}\")\n",
    "            # Actualizar estado de botones (habilita Ejecutar si hay ruta)\n",
    "            self._set_ui_state('enabled')\n",
    "        else:\n",
    "             # Si canceló y no había ruta previa, asegurar que Ejecutar esté deshabilitado\n",
    "             if not self.file_path.get():\n",
    "                 self._set_ui_state('disabled') # Llama a set_ui_state para manejar la lógica\n",
    "\n",
    "    # --- Lógica Principal de Procesamiento ---\n",
    "\n",
    "    def _start_processing(self) -> None:\n",
    "        \"\"\"Valida e inicia el proceso de análisis en un hilo.\"\"\"\n",
    "        if not self.file_path.get():\n",
    "            messagebox.showwarning(\"Archivo no seleccionado\", \"Selecciona un archivo Excel.\", parent=self.root)\n",
    "            return\n",
    "        if self.processing_thread and self.processing_thread.is_alive():\n",
    "            messagebox.showwarning(\"Proceso en ejecución\", \"Análisis ya en curso.\", parent=self.root)\n",
    "            return\n",
    "\n",
    "        # --- Verificación Crítica Pre-vuelo ---\n",
    "        is_ok, message, found_model_name = self._verify_ollama_model()\n",
    "        if not is_ok:\n",
    "            self._log_message(f\"ERROR CRÍTICO (Pre-vuelo): {message}\", level=\"ERROR\")\n",
    "            messagebox.showerror(\"Error Crítico Ollama\", f\"No se puede iniciar el proceso.\\n{message}\", parent=self.root)\n",
    "            return\n",
    "        else:\n",
    "            self._log_message(f\"Verificación pre-vuelo OK. Modelo a usar: {found_model_name}\")\n",
    "            self.actual_model_to_use = found_model_name # Asegurarse de usar el nombre completo\n",
    "\n",
    "        # --- Preparar e Iniciar Hilo ---\n",
    "        self._set_ui_state('processing') # Cambia estado a procesando (habilita Cancelar)\n",
    "        self._update_progress(0)\n",
    "        self.gemma_summary_errors = 0\n",
    "        self.gemma_classification_errors = 0\n",
    "        self.processed_count = 0\n",
    "        self.total_tickets_to_process = 0\n",
    "        self.start_time = time.time()\n",
    "        self.cancel_requested.clear() # Asegura que no esté cancelado de ejecuciones previas\n",
    "\n",
    "        # Limpiar log\n",
    "        if self.log_text.winfo_exists():\n",
    "            self.log_text.config(state=tk.NORMAL); self.log_text.delete('1.0', tk.END); self.log_text.config(state=tk.DISABLED)\n",
    "\n",
    "        self._log_message(f\"Iniciando análisis paralelo (hasta {MAX_WORKERS} hilos)...\")\n",
    "        self._log_message(f\"Usando modelo LLM: {self.actual_model_to_use}\")\n",
    "\n",
    "        # Iniciar hilo worker\n",
    "        self.processing_thread = threading.Thread(target=self._process_tickets_worker, name=\"WorkerThread\", daemon=True)\n",
    "        self.processing_thread.start()\n",
    "\n",
    "    def _request_cancel(self) -> None:\n",
    "        \"\"\"Señaliza la solicitud de cancelación.\"\"\"\n",
    "        if self.processing_thread and self.processing_thread.is_alive():\n",
    "            self._log_message(\"Solicitud de cancelación recibida...\", level=\"WARNING\")\n",
    "            self.cancel_requested.set()\n",
    "            if self.cancel_button and self.cancel_button.winfo_exists():\n",
    "                 self.cancel_button.config(state=tk.DISABLED) # Deshabilitar tras pulsar\n",
    "        else:\n",
    "            self._log_message(\"No hay proceso activo para cancelar.\", level=\"INFO\")\n",
    "\n",
    "    def _process_single_ticket(self, ticket_data: Any) -> Tuple[int, str, str, str]:\n",
    "        \"\"\"\n",
    "        Procesa un único ticket (limpieza, llamadas LLM).\n",
    "        Se ejecuta en un hilo del ThreadPoolExecutor.\n",
    "        Args:\n",
    "            ticket_data: Un objeto NamedTuple de df.itertuples() que representa una fila.\n",
    "        Returns:\n",
    "            Tuple[int, str, str, str]: (índice_original, número_ticket, resultado_resumen, resultado_clasificación)\n",
    "        \"\"\"\n",
    "        original_index = ticket_data.Index\n",
    "        ticket_number = str(getattr(ticket_data, 'Number', f'Fila_{original_index + 1}'))\n",
    "\n",
    "        # Verificar cancelación al inicio de la tarea\n",
    "        if self.cancel_requested.is_set():\n",
    "            return original_index, ticket_number, \"OPERACION_CANCELADA\", \"OPERACION_CANCELADA\"\n",
    "\n",
    "        try:\n",
    "            # --- Combinar y Limpiar Texto ---\n",
    "            short_desc = str(getattr(ticket_data, 'Short_description', '')) # Ojo: itertuples puede renombrar columnas con espacios\n",
    "            description = str(getattr(ticket_data, 'Description', ''))\n",
    "            work_notes = str(getattr(ticket_data, 'Work_notes', ''))\n",
    "            # Revisa los nombres exactos que genera itertuples si fallan los getattr\n",
    "            # Puedes imprimir `dir(ticket_data)` la primera vez para verlos.\n",
    "            # Si tienen caracteres especiales, usa getattr(ticket_data, 'Nombre Columna')\n",
    "\n",
    "            combined_text = f\"Título: {short_desc}\\n\\nDescripción:\\n{description}\\n\\nNotas de trabajo:\\n{work_notes}\"\n",
    "            cleaned_text = clean_text(combined_text)\n",
    "\n",
    "            # --- Procesar si hay texto ---\n",
    "            if not cleaned_text.strip():\n",
    "                logging.warning(f\"T:{ticket_number} - Texto vacío tras limpieza.\")\n",
    "                return original_index, ticket_number, EMPTY_TEXT_MARKER, EMPTY_TEXT_MARKER\n",
    "\n",
    "            # Verificar cancelación antes de llamadas LLM\n",
    "            if self.cancel_requested.is_set(): return original_index, ticket_number, \"OPERACION_CANCELADA\", \"OPERACION_CANCELADA\"\n",
    "\n",
    "            # --- 1. Generar Resumen ---\n",
    "            summary_prompt = PROMPT_GEMMA_SUMMARY.format(ticket_text=cleaned_text)\n",
    "            gemma_summary = call_ollama_with_retry(self.actual_model_to_use, summary_prompt)\n",
    "\n",
    "            if self.cancel_requested.is_set(): return original_index, ticket_number, \"OPERACION_CANCELADA\", \"OPERACION_CANCELADA\"\n",
    "\n",
    "             # --- 2. Generar Clasificación ---\n",
    "            classification_prompt = PROMPT_GEMMA_CLASSIFICATION.format(ticket_text=cleaned_text)\n",
    "            gemma_classification = call_ollama_with_retry(self.actual_model_to_use, classification_prompt)\n",
    "\n",
    "            # Limpieza básica de clasificación (si no es error ni cancelado)\n",
    "            if not gemma_classification.startswith(\"ERROR_\") and gemma_classification != \"OPERACION_CANCELADA\":\n",
    "                gemma_classification = gemma_classification.lstrip(\"-* \").strip()\n",
    "\n",
    "            return original_index, ticket_number, gemma_summary, gemma_classification\n",
    "\n",
    "        except Exception as e:\n",
    "            # Capturar cualquier error inesperado DENTRO del procesamiento de UN ticket\n",
    "            logging.error(f\"Error inesperado procesando T:{ticket_number} (Índice: {original_index}): {e}\\n{traceback.format_exc()}\")\n",
    "            return original_index, ticket_number, PROCESSING_ERROR_MARKER, PROCESSING_ERROR_MARKER\n",
    "\n",
    "\n",
    "    def _process_tickets_worker(self) -> None:\n",
    "        \"\"\"Worker principal: lee Excel, gestiona pool de hilos, guarda resultados.\"\"\"\n",
    "        df = None\n",
    "        summaries_map: Dict[int, str] = {} # Usar diccionarios para mapear índice a resultado\n",
    "        classifications_map: Dict[int, str] = {}\n",
    "\n",
    "        try:\n",
    "            file_path = self.file_path.get()\n",
    "            self._log_message(f\"Leyendo archivo: {os.path.basename(file_path)}\", level=\"INFO\")\n",
    "\n",
    "            # --- Lectura y Validación ---\n",
    "            try:\n",
    "                df = pd.read_excel(file_path, engine='openpyxl')\n",
    "            # (Manejo de errores de lectura como antes)\n",
    "            except FileNotFoundError:\n",
    "                self._log_message(f\"Error: Archivo no encontrado: {file_path}\", level=\"ERROR\"); self.root.after(0, lambda: messagebox.showerror(\"Error\", f\"Archivo no encontrado:\\n{file_path}\", parent=self.root)); self._finalize_processing(); return\n",
    "            except Exception as e:\n",
    "                self._log_message(f\"Error al leer Excel: {e}\\n{traceback.format_exc()}\", level=\"ERROR\"); self.root.after(0, lambda: messagebox.showerror(\"Error Lectura\", f\"No se pudo leer Excel:\\n{e}\", parent=self.root)); self._finalize_processing(); return\n",
    "\n",
    "            # Validar columnas (¡importante!)\n",
    "            # Limpiar nombres de columnas del DF para comparación robusta\n",
    "            df.columns = [col.strip() for col in df.columns]\n",
    "            missing_cols = [col for col in REQUIRED_COLUMNS if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                missing_cols_str = ', '.join(missing_cols)\n",
    "                self._log_message(f\"Error: Faltan columnas: {missing_cols_str}\", level=\"ERROR\")\n",
    "                self.root.after(0, lambda: messagebox.showerror(\"Error Columnas\", f\"Faltan columnas requeridas:\\n{missing_cols_str}\", parent=self.root))\n",
    "                self._finalize_processing(); return\n",
    "\n",
    "            self.total_tickets_to_process = len(df)\n",
    "            if self.total_tickets_to_process == 0:\n",
    "                self._log_message(\"Archivo Excel vacío.\", level=\"WARNING\"); self.root.after(0, lambda: messagebox.showwarning(\"Archivo Vacío\", \"Excel no contiene tickets.\", parent=self.root)); self._finalize_processing(); return\n",
    "\n",
    "            # Configurar máximo de la barra de progreso\n",
    "            self.root.after(0, lambda: self.progress_bar.config(maximum=self.total_tickets_to_process))\n",
    "            self._log_message(f\"Validación OK. Total tickets a procesar: {self.total_tickets_to_process}\")\n",
    "\n",
    "            # --- Procesamiento Paralelo ---\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS, thread_name_prefix='TicketProcessor') as executor:\n",
    "                # Crear futuros (tareas) para cada fila del DataFrame usando itertuples\n",
    "                # Guardar el futuro asociado a su índice original para recuperarlo después\n",
    "                # ¡Ojo! itertuples puede cambiar nombres de columnas con espacios o caracteres especiales\n",
    "                # Revisa los nombres si getattr falla en _process_single_ticket\n",
    "                futures: Dict[concurrent.futures.Future, int] = {\n",
    "                    executor.submit(self._process_single_ticket, ticket_row): ticket_row.Index\n",
    "                    for ticket_row in df.itertuples(index=True, name='TicketRow') # 'name' es opcional\n",
    "                }\n",
    "\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    original_index = futures[future] # Recuperar índice original\n",
    "                    try:\n",
    "                        # Obtener resultado de la tarea completada\n",
    "                        idx, t_num, summary_res, classification_res = future.result()\n",
    "\n",
    "                        # Almacenar resultados en los diccionarios usando el índice original\n",
    "                        summaries_map[original_index] = summary_res\n",
    "                        classifications_map[original_index] = classification_res\n",
    "\n",
    "                        # Contar errores específicos de Ollama o procesamiento interno\n",
    "                        if str(summary_res).startswith(OLLAMA_ERROR_PREFIX) or str(summary_res).startswith(UNEXPECTED_ERROR_PREFIX) or summary_res == PROCESSING_ERROR_MARKER:\n",
    "                            self.gemma_summary_errors += 1\n",
    "                            self._log_message(f\"Error resumen T:{t_num} (Índice:{idx}): {summary_res}\", level=\"ERROR\")\n",
    "                        if str(classification_res).startswith(OLLAMA_ERROR_PREFIX) or str(classification_res).startswith(UNEXPECTED_ERROR_PREFIX) or classification_res == PROCESSING_ERROR_MARKER:\n",
    "                            self.gemma_classification_errors += 1\n",
    "                            self._log_message(f\"Error clasificación T:{t_num} (Índice:{idx}): {classification_res}\", level=\"ERROR\")\n",
    "                        elif summary_res == \"OPERACION_CANCELADA\":\n",
    "                             # No contar como error, pero se puede loguear si se desea\n",
    "                             pass\n",
    "\n",
    "                        self.processed_count += 1\n",
    "                        # Actualizar progreso y log de forma segura\n",
    "                        self._update_progress(self.processed_count)\n",
    "                        if self.processed_count % 10 == 0 or self.processed_count == self.total_tickets_to_process: # Log menos frecuente\n",
    "                             self._log_message(f\"Progreso: {self.processed_count}/{self.total_tickets_to_process} tickets procesados.\")\n",
    "\n",
    "                    except Exception as exc:\n",
    "                        # Error al obtener el resultado de un futuro (raro, pero posible)\n",
    "                        self.processed_count += 1 # Contar como intentado\n",
    "                        logging.error(f\"Error al obtener resultado del futuro para índice {original_index}: {exc}\", exc_info=True)\n",
    "                        # Guardar marcadores de error para este ticket\n",
    "                        summaries_map[original_index] = f\"ERROR_FUTURO: {exc}\"\n",
    "                        classifications_map[original_index] = f\"ERROR_FUTURO: {exc}\"\n",
    "                        self.gemma_summary_errors += 1\n",
    "                        self.gemma_classification_errors += 1\n",
    "                        self._update_progress(self.processed_count)\n",
    "\n",
    "\n",
    "                    # --- Comprobar Cancelación ---\n",
    "                    # Importante comprobar *después* de procesar cada futuro\n",
    "                    if self.cancel_requested.is_set():\n",
    "                        self._log_message(\"Cancelación detectada en worker. Deteniendo envío de nuevas tareas y esperando activas...\", level=\"WARNING\")\n",
    "                        # Intentar cancelar futuros pendientes (Requiere Python 3.9+)\n",
    "                        # for f in futures:\n",
    "                        #     if not f.done(): f.cancel()\n",
    "                        # Shutdown non-blocking, permite que las tareas en ejecución terminen si no se pueden cancelar\n",
    "                        executor.shutdown(wait=False) # No esperar aquí si queremos cancelar rápido\n",
    "                        break # Salir del bucle as_completed\n",
    "\n",
    "            # --- Fin Procesamiento Paralelo ---\n",
    "\n",
    "            if self.cancel_requested.is_set():\n",
    "                 self._log_message(\"Proceso cancelado por el usuario.\", level=\"WARNING\")\n",
    "                 # No guardar archivo si se canceló (o decidir si guardar parcial)\n",
    "                 self._finalize_processing(cancelled=True)\n",
    "                 return # Salir del worker\n",
    "\n",
    "            # --- Ensamblar Resultados y Guardar ---\n",
    "            self._log_message(\"Ensamblando resultados...\")\n",
    "            if df is not None:\n",
    "                # Crear las listas de resultados ORDENADAS según el índice original del DataFrame\n",
    "                # Es crucial para que los resultados coincidan con las filas correctas\n",
    "                ordered_summaries = [summaries_map.get(i, LENGTH_MISMATCH_MARKER) for i in df.index]\n",
    "                ordered_classifications = [classifications_map.get(i, LENGTH_MISMATCH_MARKER) for i in df.index]\n",
    "\n",
    "                # Verificar si la longitud coincide (doble chequeo)\n",
    "                if len(ordered_summaries) != len(df) or len(ordered_classifications) != len(df):\n",
    "                     self._log_message(f\"¡Advertencia Crítica! Discrepancia de longitud final.\", level=\"ERROR\")\n",
    "                     # Manejar este caso extremo si ocurre (poco probable con este método)\n",
    "\n",
    "                # Añadir columnas al DataFrame\n",
    "                model_name_base = self.actual_model_to_use.split(':')[0].capitalize()\n",
    "                output_col_summary = f\"Resumen_{model_name_base}\"\n",
    "                output_col_classification = f\"Clasificacion_{model_name_base}\"\n",
    "                df[output_col_summary] = ordered_summaries\n",
    "                df[output_col_classification] = ordered_classifications\n",
    "                self._log_message(\"Resultados añadidos al DataFrame.\")\n",
    "\n",
    "                # --- Guardar Output ---\n",
    "                # (Lógica de guardado como antes, usando ask_save_path en hilo principal)\n",
    "                self._log_message(\"Solicitando ubicación para guardar...\")\n",
    "                save_path_container = {}; save_event = threading.Event()\n",
    "                def ask_save_path():\n",
    "                    try:\n",
    "                        initial_filename = os.path.basename(file_path); name, ext = os.path.splitext(initial_filename)\n",
    "                        suggested_filename=f\"{name}_analizado_clasificado_{model_name_base.lower()}{ext}\"\n",
    "                        s_path = filedialog.asksaveasfilename(parent=self.root, title=\"Guardar archivo analizado\", defaultextension=\".xlsx\", initialfile=suggested_filename, filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "                        save_path_container['path'] = s_path\n",
    "                    except Exception as e: self._log_message(f\"Error diálogo guardado: {e}\", level=\"ERROR\"); save_path_container['path'] = None\n",
    "                    finally: save_event.set()\n",
    "                self.root.after(0, ask_save_path); save_event.wait()\n",
    "                save_path = save_path_container.get('path')\n",
    "\n",
    "                if save_path:\n",
    "                    try:\n",
    "                        self._log_message(f\"Guardando archivo en: {save_path}\")\n",
    "                        df.to_excel(save_path, index=False, engine='openpyxl')\n",
    "                        self._log_message(f\"Archivo guardado exitosamente: {save_path}\")\n",
    "                        self.root.after(0, lambda: messagebox.showinfo(\"Completado\", f\"Guardado en:\\n{save_path}\", parent=self.root))\n",
    "                    except Exception as e:\n",
    "                        self._log_message(f\"Error al guardar Excel: {e}\\n{traceback.format_exc()}\", level=\"ERROR\"); self.root.after(0, lambda: messagebox.showerror(\"Error Guardar\", f\"No se pudo guardar Excel:\\n{e}\", parent=self.root))\n",
    "                else:\n",
    "                    self._log_message(\"Guardado cancelado por el usuario.\", level=\"WARNING\"); self.root.after(0, lambda: messagebox.showwarning(\"Cancelado\", \"Archivo no guardado.\", parent=self.root))\n",
    "            else:\n",
    "                self._log_message(\"Error: No hay DataFrame para guardar.\", level=\"ERROR\")\n",
    "\n",
    "        except Exception as e: # Catch-all para worker thread\n",
    "            self._log_message(f\"Error GRABE inesperado en worker: {e}\\n{traceback.format_exc()}\", level=\"ERROR\")\n",
    "            self.root.after(0, lambda: messagebox.showerror(\"Error Inesperado\", f\"Error procesamiento:\\n{e}\", parent=self.root))\n",
    "        finally:\n",
    "            # Llamar a finalizar, indicando si fue cancelado o no\n",
    "            was_cancelled = self.cancel_requested.is_set()\n",
    "            self._finalize_processing(cancelled=was_cancelled)\n",
    "\n",
    "    def _finalize_processing(self, cancelled: bool = False) -> None:\n",
    "        \"\"\"Limpia UI y loguea estadísticas finales.\"\"\"\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - (self.start_time if self.start_time else end_time)\n",
    "        model_name_used = self.actual_model_to_use\n",
    "\n",
    "        self._log_message(\"=\"*30)\n",
    "        if cancelled:\n",
    "             self._log_message(\"--- PROCESO CANCELADO ---\", level=\"WARNING\")\n",
    "        else:\n",
    "             self._log_message(\"--- PROCESO COMPLETADO ---\")\n",
    "        self._log_message(\"Estadísticas Finales:\")\n",
    "        self._log_message(f\"Tiempo total: {total_time:.2f} seg\")\n",
    "        self._log_message(f\"Tickets totales en archivo: {self.total_tickets_to_process}\")\n",
    "        self._log_message(f\"Tickets procesados (intentados): {self.processed_count}\")\n",
    "        self._log_message(f\"Errores Resumen ({model_name_used}): {self.gemma_summary_errors}\")\n",
    "        self._log_message(f\"Errores Clasificación ({model_name_used}): {self.gemma_classification_errors}\")\n",
    "\n",
    "        # Actualizar UI al estado final 'enabled' (en hilo principal)\n",
    "        self.root.after(0, self._set_ui_state, 'enabled')\n",
    "        # Asegurar que progreso refleje el final (incluso si canceló)\n",
    "        self._update_progress(self.processed_count)\n",
    "\n",
    "        # Resetear para próxima ejecución\n",
    "        self.processing_thread = None\n",
    "        self.start_time = None\n",
    "        # No limpiar cancel_requested aquí, se limpia al iniciar el *próximo* proceso\n",
    "\n",
    "# --- Ejecución Principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    # Aplicar tema (opcional pero mejora apariencia)\n",
    "    try:\n",
    "        style = ttk.Style(root)\n",
    "        available_themes = style.theme_names()\n",
    "        for theme in ['clam', 'alt', 'default', 'vista', 'xpnative']: # Probar varios comunes\n",
    "            if theme in available_themes:\n",
    "                style.theme_use(theme)\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo aplicar tema ttk: {e}\")\n",
    "\n",
    "    # Crear y lanzar la aplicación\n",
    "    # Hacer 'app' global o pasarla a funciones que necesiten acceso al estado (como call_ollama)\n",
    "    app = TicketAnalyzerApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
