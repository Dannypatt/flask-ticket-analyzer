{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30635c7-3924-446b-b33d-198dab560ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 20:32:01,246 - INFO - Archivo seleccionado: /home/danny/Downloads/Casos2.xlsx\n",
      "2025-04-18 20:32:03,151 - INFO - Iniciando procesamiento...\n",
      "2025-04-18 20:32:03,156 - INFO - Modelos disponibles en Ollama: gemma3:latest, mistral:latest, deepseek-r1:8b, gemma3:12b, llama3.2:latest, deepseek-r1:latest, deepseek-r1:14b\n",
      "2025-04-18 20:32:03,158 - INFO - Cargando archivo Excel...\n",
      "2025-04-18 20:32:03,328 - INFO - Total de tickets a procesar: 9\n",
      "2025-04-18 20:32:03,330 - INFO - Procesando ticket #SCTASK0000233249 (1/9)...\n",
      "2025-04-18 20:32:03,331 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:34:11,364 - INFO - Mistral procesado en 128.03 segundos\n",
      "2025-04-18 20:34:12,365 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:35:21,919 - INFO - Gemma3 procesado en 69.55 segundos\n",
      "2025-04-18 20:35:21,921 - INFO - Procesando ticket #SCTASK0000244189 (2/9)...\n",
      "2025-04-18 20:35:21,924 - INFO - Texto reducido de 12065 a 3554 caracteres\n",
      "2025-04-18 20:35:21,925 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:38:22,027 - INFO - Timeout en la conexi√≥n. Aumentando timeout a 300s. Reintentando en 2 segundos...\n",
      "2025-04-18 20:38:24,028 - INFO - Intentando con modelo alternativo: mistral:7b\n",
      "2025-04-18 20:38:24,030 - INFO - Enviando solicitud a mistral:7b (timeout: 300s)...\n",
      "2025-04-18 20:38:24,033 - INFO - Error en API de Ollama (c√≥digo 404). Reintentando en 4 segundos...\n",
      "2025-04-18 20:38:28,035 - INFO - Intentando con modelo alternativo: mistral\n",
      "2025-04-18 20:38:28,036 - INFO - Enviando solicitud a mistral (timeout: 300s)...\n",
      "2025-04-18 20:38:55,738 - INFO - Mistral procesado en 213.81 segundos\n",
      "2025-04-18 20:38:56,740 - INFO - Texto reducido de 12065 a 3056 caracteres\n",
      "2025-04-18 20:38:56,741 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:40:20,786 - INFO - Gemma3 procesado en 84.05 segundos\n",
      "2025-04-18 20:40:20,788 - INFO - Procesando ticket #SCTASK0000261524 (3/9)...\n",
      "2025-04-18 20:40:20,789 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:41:50,039 - INFO - Mistral procesado en 89.25 segundos\n",
      "2025-04-18 20:41:51,040 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:43:25,139 - INFO - Gemma3 procesado en 94.10 segundos\n",
      "2025-04-18 20:43:25,141 - INFO - Procesando ticket #SCTASK0000256691 (4/9)...\n",
      "2025-04-18 20:43:25,142 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:44:57,449 - INFO - Mistral procesado en 92.31 segundos\n",
      "2025-04-18 20:44:58,450 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:45:51,949 - INFO - Gemma3 procesado en 53.50 segundos\n",
      "2025-04-18 20:45:51,950 - INFO - Procesando ticket #SCTASK0000237962 (5/9)...\n",
      "2025-04-18 20:45:51,952 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:47:30,117 - INFO - Mistral procesado en 98.16 segundos\n",
      "2025-04-18 20:47:31,118 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:49:40,539 - INFO - Gemma3 procesado en 129.42 segundos\n",
      "2025-04-18 20:49:40,541 - INFO - Procesando ticket #SCTASK0000211092 (6/9)...\n",
      "2025-04-18 20:49:40,543 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:51:10,064 - INFO - Mistral procesado en 89.52 segundos\n",
      "2025-04-18 20:51:11,066 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:52:20,024 - INFO - Gemma3 procesado en 68.96 segundos\n",
      "2025-04-18 20:52:20,044 - INFO - Progreso guardado en archivo temporal: temp_progress_20250418_205220.xlsx\n",
      "2025-04-18 20:52:20,045 - INFO - Procesando ticket #SCTASK0000219733 (7/9)...\n",
      "2025-04-18 20:52:20,046 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:53:33,462 - INFO - Mistral procesado en 73.42 segundos\n",
      "2025-04-18 20:53:34,463 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:54:56,715 - INFO - Gemma3 procesado en 82.25 segundos\n",
      "2025-04-18 20:54:56,717 - INFO - Procesando ticket #SCTASK0000259420 (8/9)...\n",
      "2025-04-18 20:54:56,718 - INFO - Texto reducido de 3999 a 3554 caracteres\n",
      "2025-04-18 20:54:56,719 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 20:56:59,012 - INFO - Mistral procesado en 122.29 segundos\n",
      "2025-04-18 20:57:00,014 - INFO - Texto reducido de 3999 a 3056 caracteres\n",
      "2025-04-18 20:57:00,015 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 20:58:24,830 - INFO - Gemma3 procesado en 84.82 segundos\n",
      "2025-04-18 20:58:24,832 - INFO - Procesando ticket #SCTASK0000230550 (9/9)...\n",
      "2025-04-18 20:58:24,833 - INFO - Enviando solicitud a mistral (timeout: 180s)...\n",
      "2025-04-18 21:00:22,643 - INFO - Mistral procesado en 117.81 segundos\n",
      "2025-04-18 21:00:23,645 - INFO - Enviando solicitud a gemma3 (timeout: 180s)...\n",
      "2025-04-18 21:01:31,413 - INFO - Gemma3 procesado en 67.77 segundos\n",
      "2025-04-18 22:01:30,693 - INFO - Resultados guardados exitosamente en: /home/danny/Downloads/Casos2_Nuevo.xlsx\n",
      "2025-04-18 22:01:30,694 - INFO - \n",
      "Estad√≠sticas finales:\n",
      "2025-04-18 22:01:30,696 - INFO - Tiempo total: 5367.54 segundos\n",
      "2025-04-18 22:01:30,697 - INFO - Tickets procesados: 9/9\n",
      "2025-04-18 22:01:30,698 - INFO - Errores con Mistral: 0\n",
      "2025-04-18 22:01:30,700 - INFO - Errores con Gemma3: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('ticket_analyzer.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TicketAnalyzer:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Analizador de Tickets IT\")\n",
    "        self.root.geometry(\"600x400\")\n",
    "        self.root.resizable(False, False)\n",
    "        \n",
    "        # Variables\n",
    "        self.file_path = tk.StringVar()\n",
    "        self.processing = False\n",
    "        self.cancel_requested = False\n",
    "        self.required_columns = [\n",
    "            'Number', 'Priority', 'State', 'Assigned to', 'Short description',\n",
    "            'Task type', 'Subcategory', 'Closed', 'Created', 'Assignment group',\n",
    "            'Work notes list', 'Work notes', 'Description'\n",
    "        ]\n",
    "        \n",
    "        # Cache para respuestas LLM\n",
    "        self.mistral_cache = {}\n",
    "        self.gemma3_cache = {}\n",
    "        \n",
    "        self.create_widgets()\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        # Frame superior - Selecci√≥n de archivo\n",
    "        top_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        top_frame.pack(fill=tk.X)\n",
    "        \n",
    "        ttk.Label(top_frame, text=\"Seleccionar archivo Excel:\").pack(side=tk.LEFT, padx=(0, 5))\n",
    "        ttk.Entry(top_frame, textvariable=self.file_path, width=40, state=\"readonly\").pack(side=tk.LEFT, padx=(0, 5))\n",
    "        ttk.Button(top_frame, text=\"üñø\", command=self.browse_file, width=3).pack(side=tk.LEFT)\n",
    "        \n",
    "        # Frame central - Logs y progreso\n",
    "        center_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        center_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Text area para logs con scrollbar\n",
    "        self.log_text = tk.Text(center_frame, height=15, wrap=tk.WORD)\n",
    "        scrollbar = ttk.Scrollbar(center_frame, command=self.log_text.yview)\n",
    "        self.log_text.configure(yscrollcommand=scrollbar.set)\n",
    "        self.log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        \n",
    "        # Frame para la barra de progreso\n",
    "        progress_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        progress_frame.pack(fill=tk.X)\n",
    "        \n",
    "        self.progress_label = ttk.Label(progress_frame, text=\"Progreso: 0%\")\n",
    "        self.progress_label.pack(side=tk.TOP, anchor=tk.W)\n",
    "        \n",
    "        self.progress_bar = ttk.Progressbar(progress_frame, orient=tk.HORIZONTAL, length=580, mode='determinate')\n",
    "        self.progress_bar.pack(fill=tk.X)\n",
    "        \n",
    "        # Frame inferior - Botones de acci√≥n\n",
    "        bottom_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        bottom_frame.pack(fill=tk.X)\n",
    "        \n",
    "        self.process_button = ttk.Button(bottom_frame, text=\"‚ñ∂ Ejecutar Proceso\", command=self.start_processing)\n",
    "        self.process_button.pack(side=tk.LEFT, padx=(0, 5))\n",
    "        \n",
    "        self.cancel_button = ttk.Button(bottom_frame, text=\"‚èπ Cancelar\", command=self.cancel_processing, state=tk.DISABLED)\n",
    "        self.cancel_button.pack(side=tk.LEFT)\n",
    "        \n",
    "        # Bot√≥n para probar un solo ticket\n",
    "        self.test_button = ttk.Button(bottom_frame, text=\"üß™ Probar (1 ticket)\", command=self.test_single_ticket)\n",
    "        self.test_button.pack(side=tk.RIGHT)\n",
    "        \n",
    "    def browse_file(self):\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Seleccionar archivo Excel\",\n",
    "            filetypes=[(\"Archivos Excel\", \"*.xlsx\")]\n",
    "        )\n",
    "        if file_path:\n",
    "            self.file_path.set(file_path)\n",
    "            self.log_message(f\"Archivo seleccionado: {file_path}\")\n",
    "    \n",
    "    def log_message(self, message):\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        self.log_text.insert(tk.END, f\"[{timestamp}] {message}\\n\")\n",
    "        self.log_text.see(tk.END)\n",
    "        logger.info(message)\n",
    "    \n",
    "    def start_processing(self):\n",
    "        if not self.file_path.get():\n",
    "            messagebox.showerror(\"Error\", \"Por favor seleccione un archivo Excel primero.\")\n",
    "            return\n",
    "        \n",
    "        if self.processing:\n",
    "            return\n",
    "            \n",
    "        self.processing = True\n",
    "        self.cancel_requested = False\n",
    "        self.process_button.config(state=tk.DISABLED)\n",
    "        self.test_button.config(state=tk.DISABLED)\n",
    "        self.cancel_button.config(state=tk.NORMAL)\n",
    "        \n",
    "        # Iniciar procesamiento en un hilo separado\n",
    "        processing_thread = threading.Thread(target=self.process_file)\n",
    "        processing_thread.daemon = True\n",
    "        processing_thread.start()\n",
    "    \n",
    "    def test_single_ticket(self):\n",
    "        \"\"\"Procesa solo el primer ticket para pruebas\"\"\"\n",
    "        if not self.file_path.get():\n",
    "            messagebox.showerror(\"Error\", \"Por favor seleccione un archivo Excel primero.\")\n",
    "            return\n",
    "        \n",
    "        if self.processing:\n",
    "            return\n",
    "            \n",
    "        self.processing = True\n",
    "        self.cancel_requested = False\n",
    "        self.process_button.config(state=tk.DISABLED)\n",
    "        self.test_button.config(state=tk.DISABLED)\n",
    "        self.cancel_button.config(state=tk.NORMAL)\n",
    "        \n",
    "        # Iniciar procesamiento en un hilo separado\n",
    "        test_thread = threading.Thread(target=self.process_test_ticket)\n",
    "        test_thread.daemon = True\n",
    "        test_thread.start()\n",
    "    \n",
    "    def process_test_ticket(self):\n",
    "        \"\"\"Procesa solo el primer ticket para pruebas\"\"\"\n",
    "        try:\n",
    "            # Verificar conexi√≥n con Ollama\n",
    "            if not self.check_ollama_connection():\n",
    "                self.log_message(\"ERROR: No se pudo conectar con el servidor Ollama. Verifique que est√° ejecut√°ndose.\")\n",
    "                self.reset_ui()\n",
    "                return\n",
    "\n",
    "            # Cargar archivo Excel\n",
    "            self.log_message(\"Cargando archivo Excel...\")\n",
    "            df = pd.read_excel(self.file_path.get())\n",
    "            \n",
    "            # Validar columnas requeridas\n",
    "            missing_columns = [col for col in self.required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                self.log_message(f\"ERROR: Faltan columnas requeridas: {', '.join(missing_columns)}\")\n",
    "                self.reset_ui()\n",
    "                return\n",
    "                \n",
    "            # Tomar solo el primer ticket\n",
    "            if len(df) > 0:\n",
    "                row = df.iloc[0]\n",
    "                ticket_num = row['Number']\n",
    "                self.log_message(f\"PRUEBA: Procesando ticket #{ticket_num}\")\n",
    "                \n",
    "                # Limpiar texto para el an√°lisis\n",
    "                try:\n",
    "                    short_desc = str(row['Short description']) if not pd.isna(row['Short description']) else \"\"\n",
    "                    work_notes = str(row['Work notes']) if not pd.isna(row['Work notes']) else \"\"\n",
    "                    description = str(row['Description']) if not pd.isna(row['Description']) else \"\"\n",
    "                    \n",
    "                    # Imprimir informaci√≥n del texto\n",
    "                    self.log_message(f\"Longitud de Short description: {len(short_desc)} caracteres\")\n",
    "                    self.log_message(f\"Longitud de Work notes: {len(work_notes)} caracteres\")\n",
    "                    self.log_message(f\"Longitud de Description: {len(description)} caracteres\")\n",
    "                    \n",
    "                    # Combinar texto y limpiarlo\n",
    "                    combined_text = f\"Ticket: {ticket_num}\\nDescripci√≥n Corta: {short_desc}\\nNotas de Trabajo: {work_notes}\\nDescripci√≥n: {description}\"\n",
    "                    cleaned_text = self.clean_text(combined_text)\n",
    "                    self.log_message(f\"Longitud de texto combinado y limpio: {len(cleaned_text)} caracteres\")\n",
    "                    \n",
    "                    # Clasificar con Mistral\n",
    "                    self.log_message(\"Probando modelo Mistral...\")\n",
    "                    mistral_result = self.process_with_mistral(cleaned_text)\n",
    "                    self.log_message(\"‚úì Respuesta de Mistral recibida correctamente\")\n",
    "                    self.log_message(f\"Longitud de respuesta Mistral: {len(mistral_result)} caracteres\")\n",
    "                    \n",
    "                    # Resumir con Gemma3\n",
    "                    self.log_message(\"Probando modelo Gemma3...\")\n",
    "                    gemma3_result = self.process_with_gemma3(cleaned_text)\n",
    "                    self.log_message(\"‚úì Respuesta de Gemma3 recibida correctamente\")\n",
    "                    self.log_message(f\"Longitud de respuesta Gemma3: {len(gemma3_result)} caracteres\")\n",
    "                    \n",
    "                    self.log_message(\"PRUEBA COMPLETADA EXITOSAMENTE ‚úì\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log_message(f\"ERROR en prueba: {str(e)}\")\n",
    "            else:\n",
    "                self.log_message(\"ERROR: El archivo Excel no contiene tickets.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.log_message(f\"ERROR GENERAL: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            self.reset_ui()\n",
    "    \n",
    "    def cancel_processing(self):\n",
    "        if self.processing:\n",
    "            self.cancel_requested = True\n",
    "            self.log_message(\"Cancelaci√≥n solicitada. Espere a que finalice el procesamiento actual...\")\n",
    "            self.cancel_button.config(state=tk.DISABLED)\n",
    "    \n",
    "    def process_file(self):\n",
    "        start_time = time.time()\n",
    "        self.log_message(\"Iniciando procesamiento...\")\n",
    "        \n",
    "        try:\n",
    "            # Verificar conexi√≥n con Ollama\n",
    "            if not self.check_ollama_connection():\n",
    "                self.log_message(\"ERROR: No se pudo conectar con el servidor Ollama. Verifique que est√° ejecut√°ndose.\")\n",
    "                self.reset_ui()\n",
    "                return\n",
    "                \n",
    "            # Cargar archivo Excel\n",
    "            self.log_message(\"Cargando archivo Excel...\")\n",
    "            df = pd.read_excel(self.file_path.get())\n",
    "            \n",
    "            # Validar columnas requeridas\n",
    "            missing_columns = [col for col in self.required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                self.log_message(f\"ERROR: Faltan columnas requeridas: {', '.join(missing_columns)}\")\n",
    "                self.reset_ui()\n",
    "                return\n",
    "            \n",
    "            # Preparar para el procesamiento\n",
    "            total_tickets = len(df)\n",
    "            self.log_message(f\"Total de tickets a procesar: {total_tickets}\")\n",
    "            \n",
    "            # Crear nuevas columnas para resultados\n",
    "            df['DescripcionMistral'] = \"\"\n",
    "            df['ResumenGemma3'] = \"\"\n",
    "            \n",
    "            # Procesar tickets\n",
    "            errors_mistral = 0\n",
    "            errors_gemma3 = 0\n",
    "            processed_count = 0\n",
    "            \n",
    "            for index, row in df.iterrows():\n",
    "                if self.cancel_requested:\n",
    "                    self.log_message(\"Proceso cancelado por el usuario.\")\n",
    "                    break\n",
    "                \n",
    "                ticket_num = row['Number']\n",
    "                self.log_message(f\"Procesando ticket #{ticket_num} ({index + 1}/{total_tickets})...\")\n",
    "                \n",
    "                # Limpiar texto para el an√°lisis\n",
    "                try:\n",
    "                    short_desc = str(row['Short description']) if not pd.isna(row['Short description']) else \"\"\n",
    "                    work_notes = str(row['Work notes']) if not pd.isna(row['Work notes']) else \"\"\n",
    "                    description = str(row['Description']) if not pd.isna(row['Description']) else \"\"\n",
    "                    \n",
    "                    # Combinar texto y limpiarlo\n",
    "                    combined_text = f\"Ticket: {ticket_num}\\nDescripci√≥n Corta: {short_desc}\\nNotas de Trabajo: {work_notes}\\nDescripci√≥n: {description}\"\n",
    "                    cleaned_text = self.clean_text(combined_text)\n",
    "                    \n",
    "                    # Clasificar con Mistral\n",
    "                    mistral_start = time.time()\n",
    "                    mistral_result = self.process_with_mistral(cleaned_text)\n",
    "                    mistral_time = time.time() - mistral_start\n",
    "                    df.at[index, 'DescripcionMistral'] = mistral_result\n",
    "                    self.log_message(f\"Mistral procesado en {mistral_time:.2f} segundos\")\n",
    "                    \n",
    "                    # Para evitar sobrecarga, esperar un momento\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Resumir con Gemma3\n",
    "                    gemma_start = time.time()\n",
    "                    gemma3_result = self.process_with_gemma3(cleaned_text)\n",
    "                    gemma_time = time.time() - gemma_start\n",
    "                    df.at[index, 'ResumenGemma3'] = gemma3_result\n",
    "                    self.log_message(f\"Gemma3 procesado en {gemma_time:.2f} segundos\")\n",
    "                    \n",
    "                    # Guardar progresivamente para no perder datos\n",
    "                    if index % 5 == 0 and index > 0:\n",
    "                        self.save_progress(df)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log_message(f\"Error procesando ticket #{ticket_num}: {str(e)}\")\n",
    "                    if \"mistral\" in str(e).lower():\n",
    "                        errors_mistral += 1\n",
    "                    if \"gemma\" in str(e).lower():\n",
    "                        errors_gemma3 += 1\n",
    "                \n",
    "                # Actualizar progreso cada ticket\n",
    "                processed_count += 1\n",
    "                progress = int((processed_count / total_tickets) * 100)\n",
    "                self.update_progress(progress)\n",
    "            \n",
    "            # Guardar resultados finales\n",
    "            if not self.cancel_requested:\n",
    "                self.save_results(df)\n",
    "                \n",
    "            # Estad√≠sticas finales\n",
    "            end_time = time.time()\n",
    "            total_time = end_time - start_time\n",
    "            self.log_message(f\"\\nEstad√≠sticas finales:\")\n",
    "            self.log_message(f\"Tiempo total: {total_time:.2f} segundos\")\n",
    "            self.log_message(f\"Tickets procesados: {processed_count}/{total_tickets}\")\n",
    "            self.log_message(f\"Errores con Mistral: {errors_mistral}\")\n",
    "            self.log_message(f\"Errores con Gemma3: {errors_gemma3}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.log_message(f\"ERROR GENERAL: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            self.reset_ui()\n",
    "    \n",
    "    def check_ollama_connection(self):\n",
    "        try:\n",
    "            response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get(\"models\", [])\n",
    "                mistral_found = any(\"mistral\" in model[\"name\"].lower() for model in models)\n",
    "                gemma_found = any(\"gemma\" in model[\"name\"].lower() for model in models)\n",
    "                \n",
    "                if not mistral_found:\n",
    "                    self.log_message(\"ADVERTENCIA: Modelo 'mistral' no encontrado espec√≠ficamente en Ollama\")\n",
    "                if not gemma_found:\n",
    "                    self.log_message(\"ADVERTENCIA: Modelo 'gemma3' no encontrado espec√≠ficamente en Ollama\")\n",
    "                \n",
    "                # Listar modelos disponibles\n",
    "                model_names = [model[\"name\"] for model in models]\n",
    "                self.log_message(f\"Modelos disponibles en Ollama: {', '.join(model_names)}\")\n",
    "                \n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            self.log_message(f\"Error al verificar conexi√≥n con Ollama: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Limpia el texto de patrones y HTML\"\"\"\n",
    "        # Eliminar patrones [ARGONAUTA] y [INC...]\n",
    "        text = re.sub(r'\\[ARGONAUTA\\]|\\[INC[^\\]]*\\]', '', text)\n",
    "        \n",
    "        # Remover HTML\n",
    "        try:\n",
    "            soup = BeautifulSoup(text, 'html.parser')\n",
    "            text = soup.get_text(separator=' ')\n",
    "        except Exception as e:\n",
    "            self.log_message(f\"Advertencia al limpiar HTML: {str(e)}\")\n",
    "            pass\n",
    "        \n",
    "        # Eliminar espacios extra y normalizar\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def prepare_text_for_llm(self, text, max_length=3500):\n",
    "        \"\"\"Prepara el texto para enviar al LLM, recortando si es necesario\"\"\"\n",
    "        if len(text) <= max_length:\n",
    "            return text\n",
    "        \n",
    "        # Estrategia de recorte inteligente\n",
    "        # Mantener el inicio y el final que suelen contener info importante\n",
    "        start_portion = max_length // 3 * 2  # 2/3 del inicio\n",
    "        end_portion = max_length // 3        # 1/3 del final\n",
    "        middle_indicator = \"... [contenido omitido para optimizar procesamiento] ...\"\n",
    "        \n",
    "        result = text[:start_portion] + middle_indicator + text[-end_portion:]\n",
    "        self.log_message(f\"Texto reducido de {len(text)} a {len(result)} caracteres\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_with_mistral(self, text):\n",
    "        \"\"\"Procesa el texto con el modelo Mistral\"\"\"\n",
    "        # Verificar cache\n",
    "        cache_key = hash(text)\n",
    "        if cache_key in self.mistral_cache:\n",
    "            self.log_message(\"Usando resultado de cache para Mistral\")\n",
    "            return self.mistral_cache[cache_key]\n",
    "        \n",
    "        # Preparar texto optimizado\n",
    "        prepared_text = self.prepare_text_for_llm(text)\n",
    "        \n",
    "        prompt = f\"\"\"Clasifica este ticket de IT seg√∫n categor√≠as t√©cnicas:\n",
    "Descripci√≥n: {prepared_text}\n",
    "Considerar: Lo que se encuentra en la columna Short description, Work notes y Description, para hacer un analisis del ticket y poder clasificar el ticket\n",
    "Formato: JSON con clasificaci√≥n y razonamiento\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.call_ollama_api(\"mistral\", prompt)\n",
    "            \n",
    "            # Intentar extraer JSON de la respuesta\n",
    "            json_result = self.extract_json(response)\n",
    "            if json_result:\n",
    "                result_str = json.dumps(json_result, ensure_ascii=False)\n",
    "                # Guardar en cache\n",
    "                self.mistral_cache[cache_key] = result_str\n",
    "                return result_str\n",
    "            else:\n",
    "                formatted_response = self.format_response(response)\n",
    "                # Guardar en cache\n",
    "                self.mistral_cache[cache_key] = formatted_response\n",
    "                return formatted_response\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error con Mistral: {str(e)}\")\n",
    "    \n",
    "    def process_with_gemma3(self, text):\n",
    "        \"\"\"Procesa el texto con el modelo Gemma3\"\"\"\n",
    "        # Verificar cache\n",
    "        cache_key = hash(text)\n",
    "        if cache_key in self.gemma3_cache:\n",
    "            self.log_message(\"Usando resultado de cache para Gemma3\")\n",
    "            return self.gemma3_cache[cache_key]\n",
    "        \n",
    "        # Preparar texto optimizado\n",
    "        prepared_text = self.prepare_text_for_llm(text, max_length=3000)\n",
    "        \n",
    "        prompt = f\"\"\"Resume este ticket para an√°lisis de tendencias:\n",
    "{prepared_text}\n",
    "M√°ximo 3 puntos clave t√©cnicos\n",
    "Identificar posible causa ra√≠z\n",
    "Formato: Vi√±etas concisas\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.call_ollama_api(\"gemma3\", prompt)\n",
    "            formatted_response = self.format_response(response)\n",
    "            \n",
    "            # Guardar en cache\n",
    "            self.gemma3_cache[cache_key] = formatted_response\n",
    "            return formatted_response\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error con Gemma3: {str(e)}\")\n",
    "    \n",
    "    def call_ollama_api(self, model, prompt, max_retries=3):\n",
    "        \"\"\"Llama a la API de Ollama con reintentos y timeout extendido\"\"\"\n",
    "        url = \"http://localhost:11434/api/generate\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        \n",
    "        # Truncar el prompt si es demasiado largo\n",
    "        if len(prompt) > 4000:\n",
    "            self.log_message(f\"Prompt truncado de {len(prompt)} a 4000 caracteres\")\n",
    "            prompt = prompt[:4000] + \"... [contenido truncado]\"\n",
    "        \n",
    "        # Si el modelo es gemma3 pero no est√° disponible, intentar con gemma:2b\n",
    "        if model == \"gemma3\":\n",
    "            model_alternatives = [\"gemma3\", \"gemma:2b\", \"gemma\", \"gemma:7b\"]\n",
    "        else:\n",
    "            model_alternatives = [model, \"mistral:7b\", \"mistral\", \"llama3\"]\n",
    "        \n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        retry_count = 0\n",
    "        timeout_value = 180  # Aumentado a 3 minutos\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                # Intentar con modelo alternativo si es necesario\n",
    "                if retry_count > 0 and retry_count < len(model_alternatives):\n",
    "                    current_model = model_alternatives[retry_count]\n",
    "                    data[\"model\"] = current_model\n",
    "                    self.log_message(f\"Intentando con modelo alternativo: {current_model}\")\n",
    "                \n",
    "                self.log_message(f\"Enviando solicitud a {data['model']} (timeout: {timeout_value}s)...\")\n",
    "                response = requests.post(url, headers=headers, json=data, timeout=timeout_value)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    return response.json().get(\"response\", \"\")\n",
    "                else:\n",
    "                    retry_count += 1\n",
    "                    wait_time = 2 ** retry_count  # Backoff exponencial\n",
    "                    self.log_message(f\"Error en API de Ollama (c√≥digo {response.status_code}). Reintentando en {wait_time} segundos...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    \n",
    "            except requests.exceptions.Timeout:\n",
    "                # Espec√≠ficamente para timeouts, aumentamos el timeout para el siguiente intento\n",
    "                retry_count += 1\n",
    "                timeout_value += 120  # Incrementar en 2 minutos cada vez\n",
    "                wait_time = 2 ** retry_count\n",
    "                self.log_message(f\"Timeout en la conexi√≥n. Aumentando timeout a {timeout_value}s. Reintentando en {wait_time} segundos...\")\n",
    "                time.sleep(wait_time)\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                wait_time = 2 ** retry_count\n",
    "                self.log_message(f\"Error de conexi√≥n: {str(e)}. Reintentando en {wait_time} segundos...\")\n",
    "                time.sleep(wait_time)\n",
    "        \n",
    "        raise Exception(f\"No se pudo obtener respuesta despu√©s de {max_retries} intentos\")\n",
    "    \n",
    "    def extract_json(self, text):\n",
    "        \"\"\"Intenta extraer un objeto JSON de la respuesta\"\"\"\n",
    "        try:\n",
    "            # Buscar texto entre {} con regex\n",
    "            json_match = re.search(r'\\{.+\\}', text, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "                return json.loads(json_str)\n",
    "            \n",
    "            # Si no funciona, intentar con toda la respuesta\n",
    "            return json.loads(text)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def format_response(self, text):\n",
    "        \"\"\"Formatea la respuesta para guardarla en Excel\"\"\"\n",
    "        # Limitar a 32,767 caracteres (l√≠mite de celdas Excel)\n",
    "        if len(text) > 32000:\n",
    "            text = text[:32000] + \"... (truncado)\"\n",
    "        return text\n",
    "    \n",
    "    def save_progress(self, df):\n",
    "        \"\"\"Guarda un archivo temporal de progreso\"\"\"\n",
    "        try:\n",
    "            temp_file = f\"temp_progress_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "            df.to_excel(temp_file, index=False)\n",
    "            self.log_message(f\"Progreso guardado en archivo temporal: {temp_file}\")\n",
    "        except Exception as e:\n",
    "            self.log_message(f\"Error al guardar progreso temporal: {str(e)}\")\n",
    "    \n",
    "    def save_results(self, df):\n",
    "        \"\"\"Guarda los resultados en un nuevo archivo Excel\"\"\"\n",
    "        try:\n",
    "            # Solicitar ubicaci√≥n para guardar\n",
    "            output_path = filedialog.asksaveasfilename(\n",
    "                title=\"Guardar resultados\",\n",
    "                defaultextension=\".xlsx\",\n",
    "                filetypes=[(\"Archivos Excel\", \"*.xlsx\")]\n",
    "            )\n",
    "            \n",
    "            if not output_path:\n",
    "                self.log_message(\"Guardado cancelado por el usuario.\")\n",
    "                return\n",
    "                \n",
    "            # Guardar el DataFrame a Excel\n",
    "            df.to_excel(output_path, index=False)\n",
    "            self.log_message(f\"Resultados guardados exitosamente en: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log_message(f\"Error al guardar resultados: {str(e)}\")\n",
    "    \n",
    "    def update_progress(self, value):\n",
    "        \"\"\"Actualiza la barra de progreso\"\"\"\n",
    "        self.root.after(0, lambda: self._update_progress_ui(value))\n",
    "    \n",
    "    def _update_progress_ui(self, value):\n",
    "        self.progress_bar[\"value\"] = value\n",
    "        self.progress_label.config(text=f\"Progreso: {value}%\")\n",
    "        \n",
    "    def reset_ui(self):\n",
    "        \"\"\"Restablece la interfaz despu√©s del procesamiento\"\"\"\n",
    "        self.root.after(0, lambda: self._reset_ui_internal())\n",
    "    \n",
    "    def _reset_ui_internal(self):\n",
    "        self.processing = False\n",
    "        self.process_button.config(state=tk.NORMAL)\n",
    "        self.test_button.config(state=tk.NORMAL)\n",
    "        self.cancel_button.config(state=tk.DISABLED)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = TicketAnalyzer(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
